{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b3534bf33e6bed9",
   "metadata": {},
   "source": [
    "# Causal Knowledge Transfer for Safe Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a3883d1cec1ee8",
   "metadata": {},
   "source": [
    "### Train Agents\n",
    "#### Sumo Network File\n",
    "When editing the sumo network (nets/simple_unprotected_right.net.xml) never edit the xml directly. Instead, go to nets/netconfig and make desired changes there. Generate the new net.xml by executing generate config.sh\n",
    "#### Sumo Route File\n",
    "This is part of the generate_config.sh now.\n",
    "\n",
    "**Desired Output: Trained_Model.zip**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696c12a4c9cece3a",
   "metadata": {},
   "source": [
    "### Creating the Sumo Environment"
   ]
  },
  {
   "cell_type": "code",
   "id": "e95329e734a9e91e",
   "metadata": {},
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Environment Variables (Ensure SUMO_HOME is properly set)\n",
    "sumo_home = %env SUMO_HOME\n",
    "\n",
    "# Constants / Parameters\n",
    "SPEED = 22.22\n",
    "FRICTION = 1.0\n",
    "INSERT_PROBABILITY = 0.1\n",
    "DURATION = 3600\n",
    "REPEAT_PERIOD = 10\n",
    "DEFAULT_DECEL = 4.5\n",
    "DEFAULT_EMERGENCY_DECEL = 9.0\n",
    "\n",
    "# File Paths\n",
    "config_directory = Path().joinpath('nets', '2lane_unprotected_right')\n",
    "config_files = {\n",
    "    'netccfg_edges': config_directory.joinpath('netconfig', 'edges.edg.xml'),\n",
    "    'netccfg': config_directory.joinpath('2lane_unprotected_right.netccfg'),\n",
    "    'duarcfg': config_directory.joinpath('2lane_unprotected_right.duarcfg'),\n",
    "    'net.xml': config_directory.joinpath('2lane_unprotected_right.net.xml'),\n",
    "    'rou.xml': config_directory.joinpath('2lane_unprotected_right.rou.xml'),\n",
    "    'routes.rou.xml': config_directory.joinpath('routes.rou.xml'),\n",
    "    'config.rou.xml': config_directory.joinpath('config.rou.xml'),\n",
    "    'experimental.rou.xml': config_directory.joinpath('experimental.rou.xml'),\n",
    "}\n",
    "findAllRoutes = Path(sumo_home).joinpath('tools', 'findAllRoutes.py')\n",
    "vehicle2flow = Path(sumo_home).joinpath('tools', 'route', 'vehicle2flow.py')\n",
    "\n",
    "\n",
    "# Update Friction Coefficients in Edge Configuration\n",
    "def update_friction_coefficients(file_path, friction):\n",
    "    edges_xml_tree = ET.parse(file_path)\n",
    "    edges_xml_root = edges_xml_tree.getroot()\n",
    "    for param in edges_xml_root.findall(\".//lane/param[@key='frictionCoefficient']\"):\n",
    "        param.set('value', str(friction))\n",
    "    edges_xml_tree.write(file_path)\n",
    "\n",
    "\n",
    "update_friction_coefficients(config_files['netccfg_edges'], FRICTION)\n",
    "\n",
    "# Execute SUMO Tools\n",
    "! netconvert --configuration-file {config_files['netccfg']}\n",
    "! python {findAllRoutes} -n {config_files['net.xml']} -o {config_files['routes.rou.xml']} -s southJunction,westJunction -t junctionEast,junctionNorth\n",
    "! duarouter --configuration-file {config_files['duarcfg']}\n",
    "! python {vehicle2flow} {config_files['config.rou.xml']} -o {config_files['rou.xml']} -e {DURATION} -r {REPEAT_PERIOD}\n",
    "\n",
    "# Update Vehicle Configuration for Friction Adjusted Braking Distance\n",
    "def update_vehicle_type_parameters(file_path, speed, default_decel, default_emergency_decel, friction):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    for vType in root.findall('vType'):\n",
    "        vClass = vType.attrib.get('vClass')\n",
    "        if vClass and vClass != 'passenger':\n",
    "            raise NotImplementedError(\"Check for non-passenger vehicle classes not implemented\")\n",
    "        vType.attrib.update({\n",
    "            'maxSpeed': str(speed),\n",
    "            'decel': str(default_decel * friction),\n",
    "            'emergencyDecel': str(default_emergency_decel * friction),\n",
    "        })\n",
    "    tree.write(file_path, xml_declaration=True, encoding='UTF-8')\n",
    "\n",
    "\n",
    "update_vehicle_type_parameters(config_files['rou.xml'], SPEED, DEFAULT_DECEL, DEFAULT_EMERGENCY_DECEL, FRICTION)\n",
    "\n",
    "\n",
    "# Update Vehicle Flows for Forcing Unprotected Right Action\n",
    "def update_flows(file_path, insert_probability):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    for flow in root.findall('flow'):\n",
    "        match flow.attrib.get('id'):\n",
    "            case 'southEast':\n",
    "                flow.set('period', f\"exp({insert_probability})\")\n",
    "            case 'southNorth':\n",
    "                flow.set('period', f\"exp({insert_probability})\")\n",
    "            case 'westEastTop':\n",
    "                flow.set('period', f\"exp({2 * insert_probability})\")\n",
    "            case id if 'westEastBottom' in id:\n",
    "                flow.set('end', str(float(flow.get('begin')) + 600))\n",
    "                if float(flow.get('begin')) % 1200 == 0:\n",
    "                    flow.set('period', f\"exp({1 * insert_probability})\")\n",
    "                else:\n",
    "                    flow.set('period', f\"exp({0.0001 * insert_probability})\")\n",
    "    tree.write(file_path, xml_declaration=True, encoding='UTF-8')\n",
    "\n",
    "\n",
    "update_flows(config_files['rou.xml'], INSERT_PROBABILITY)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "83958ce226f27b73",
   "metadata": {},
   "source": [
    "from env.SumoEnvironmentGenerator import SumoEnvironmentGenerator\n",
    "from pathlib import Path\n",
    "\n",
    "net_name = '2lane_unprotected_right'\n",
    "\n",
    "environments = SumoEnvironmentGenerator(\n",
    "    net_file=str(Path().joinpath('nets', net_name, f'{net_name}.net.xml')),\n",
    "    route_file=str(Path().joinpath('nets', net_name, f'{net_name}.rou.xml')),\n",
    "    sumocfg_file=str(Path().joinpath('nets', net_name, f'{net_name}.sumocfg')),\n",
    "    duration=3600,\n",
    "    learning_data_csv_name=str(Path().joinpath('env', 'training_data', 'output.csv')),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e6f9f4917eb5beff",
   "metadata": {},
   "source": [
    "### Training and saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "8c3f5ee8509cdf52",
   "metadata": {},
   "source": [
    "from stable_baselines3.a2c import A2C\n",
    "\n",
    "%load_ext tensorboard\n",
    "env = environments.get_training_env()\n",
    "model = A2C(\n",
    "    env=env,\n",
    "    policy='MlpPolicy',\n",
    "    n_steps=100,\n",
    "    # learning_rate=0.001,\n",
    "    # learning_starts=0,\n",
    "    # train_freq=1,\n",
    "    # target_update_interval=500,\n",
    "    # exploration_fraction=0.05,\n",
    "    # exploration_final_eps=0.01,\n",
    "    verbose=1,\n",
    "    tensorboard_log='tensorboard'\n",
    ")\n",
    "model_name = 'agent'\n",
    "model.learn(100_000, tb_log_name='agent')\n",
    "model.save(Path().joinpath('env', 'agents', 'agent.zip'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4604104a64fb90ae",
   "metadata": {},
   "source": [
    "Giving the model a test run in an evaluation environment"
   ]
  },
  {
   "cell_type": "code",
   "id": "4e7f9cc33d31421c",
   "metadata": {},
   "source": [
    "#63 (ns green), 86 (incoming collision), 134 (we green), 0739 unprotected good\n",
    "\n",
    "from stable_baselines3.a2c import A2C\n",
    "from pathlib import Path\n",
    "\n",
    "env = environments.get_demonstration_env()\n",
    "model = A2C(env=env, policy='MlpPolicy').load(\n",
    "    Path().joinpath('env', 'agents', 'scratch_s80_f0.5.zip'))\n",
    "\n",
    "rewards = []\n",
    "actions = []\n",
    "obs, info = env.reset()\n",
    "\n",
    "gui = env.sumo.gui\n",
    "gui.setBoundary(gui.DEFAULT_VIEW, 480.0, 480.0, 520.0, 520.0)\n",
    "# gui.addView('3D', in3D=True)\n",
    "screenshots_path_jpg = Path().joinpath('screenshots', 'tmp', 'jpg')\n",
    "screenshots_path_jpg.mkdir(parents=True, exist_ok=True)\n",
    "screenshots_path_svg = Path().joinpath('screenshots', 'tmp', 'svg')\n",
    "screenshots_path_svg.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#vehicletype = env.sumo.vehicletype\n",
    "#vehicletype.setMaxSpeed('carCustom', SPEED)\n",
    "#vehicletype.setDecel('carCustom', vehicletype.getDecel('carCustom') * FRICTION)\n",
    "#vehicletype.setEmergencyDecel('carCustom',\n",
    "#                              vehicletype.getEmergencyDecel('carCustom') * FRICTION)\n",
    "#for traffic_signal in env.traffic_signals.values():\n",
    "#    for lane in traffic_signal.lanes:\n",
    "#        traffic_signal.sumo.lane.setParameter(lane, 'frictionCoefficient', FRICTION)\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    rewards.append(reward)\n",
    "    actions.append(action)\n",
    "    done = terminated or truncated\n",
    "    current_step = int(env.sumo.simulation.getTime())\n",
    "    screenshot_path_jpg = screenshots_path_jpg.joinpath(str(current_step).zfill(4) + '.jpg')\n",
    "    screenshot_path_svg = screenshots_path_svg.joinpath(str(current_step).zfill(4) + '.svg')\n",
    "    gui.screenshot(gui.DEFAULT_VIEW, str(screenshot_path_jpg))\n",
    "    gui.screenshot(gui.DEFAULT_VIEW, str(screenshot_path_svg))\n",
    "env.close()\n",
    "\n",
    "print(rewards)\n",
    "print(\" \")\n",
    "print(actions)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4f83a5026c16fe31",
   "metadata": {},
   "source": [
    "### Produce Traces\n",
    "Run the simulation repeatably to produce traces (data) for causal discovery.\n",
    "\n",
    "\n",
    "**Desired Output: One CSV File containing all interesting data**\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3ada91211cbe194a",
   "metadata": {},
   "source": [
    "# Editable Parameters in 'env/generate.py'\n",
    "! python env/generate.py"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "237d6d2f0b9c2225",
   "metadata": {},
   "source": [
    "#### Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "id": "2e2dd00337e5afd0",
   "metadata": {},
   "source": [
    "from statistics import mean\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ElementTree\n",
    "import pandas as pd\n",
    "\n",
    "data_folder = Path().joinpath('traces')\n",
    "experiments = glob.glob(str(data_folder.joinpath('*')))\n",
    "\n",
    "for experiment in experiments:\n",
    "    experiment_path = Path(experiment)\n",
    "    statistics_files = glob.glob(str(experiment_path.joinpath('*_statistics.xml')))\n",
    "    ids = [path.split('/')[-1].split('_')[0] for path in statistics_files]\n",
    "\n",
    "    data = []\n",
    "    for id in ids:\n",
    "        statistics_file = experiment_path.joinpath(id + '_statistics.xml')\n",
    "        collisions_file = experiment_path.joinpath(id + '_collisions.xml')\n",
    "        ssm_file = experiment_path.joinpath(id + '_ssm.xml')\n",
    "        metadata_file = experiment_path.joinpath(id + '_metadata.xml')\n",
    "        tripinfo_file = experiment_path.joinpath(id + '_tripinfo.xml')\n",
    "        statistics_xml = ElementTree.parse(statistics_file).getroot()\n",
    "        collisions_xml = ElementTree.parse(collisions_file).getroot()\n",
    "        ssm_xml = ElementTree.parse(ssm_file).getroot()\n",
    "        metadata_xml = ElementTree.parse(metadata_file).getroot()\n",
    "        tripinfo_xml = ElementTree.parse(tripinfo_file).getroot()\n",
    "\n",
    "        row = {\n",
    "            'experiment': experiment,\n",
    "            'index': int(id),\n",
    "            'desiredSpeed': float(metadata_xml.find('.//desiredSpeed').text),\n",
    "            'friction': float(metadata_xml.find('.//friction').text)\n",
    "        }\n",
    "\n",
    "        for key, value in {**statistics_xml.find('vehicleTripStatistics').attrib,\n",
    "                           **statistics_xml.find('safety').attrib}.items():\n",
    "            match key:\n",
    "                case 'count' | 'emergencyStops' | 'emergencyBraking':\n",
    "                    row[key] = int(value)\n",
    "                case 'collisions':\n",
    "                    row[key] = int(value)\n",
    "                    row['rearEndCollisions'] = sum(\n",
    "                        'southEast' in child.attrib.get('victim') for child in collisions_xml)\n",
    "                    row['lateralCollisions'] = sum(\n",
    "                        'southEast' in child.attrib.get('collider') for child in collisions_xml)\n",
    "                    row[key] = row['rearEndCollisions'] + row['lateralCollisions']\n",
    "                case _:\n",
    "                    row[key] = float(value)\n",
    "\n",
    "        waiting_times = [float(tripinfo.attrib.get('waitingTime')) for tripinfo in tripinfo_xml.findall('tripinfo')]\n",
    "        average_waiting_time = mean(waiting_times)\n",
    "        row['waitingTime'] = average_waiting_time\n",
    "\n",
    "        data.append(row)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(experiment_path.joinpath('.summary.csv'), index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "12e038aa7f8f3099",
   "metadata": {},
   "source": [
    "Some Visualization"
   ]
  },
  {
   "cell_type": "code",
   "id": "e399ea7eacff5e7d",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = Path().joinpath('traces', 'traces_all_agents.csv')\n",
    "charts_path = Path().joinpath('charts')\n",
    "df = pd.read_csv(data)\n",
    "'''\n",
    "sns.displot(data=df, x='friction', y='waitingTime', kind='kde')\n",
    "plt.title('friction - waitingTime, all desiredSpeeds')\n",
    "# plt.savefig(charts_path.joinpath('friction-waitingTime.png'), bbox_inches='tight')\n",
    "\n",
    "sns.displot(data=df, x='friction', y='collisions', kind='kde')\n",
    "plt.title('friction - collisions, all desiredSpeeds')\n",
    "# plt.savefig(charts_path.joinpath('friction-collisions'), bbox_inches='tight')\n",
    "\n",
    "sns.displot(data=df, x='desiredSpeed', y='waitingTime', kind='kde')\n",
    "plt.title('desiredSpeed - waitingTime, all frictions')\n",
    "# plt.savefig(charts_path.joinpath('desiredSpeed-waitingTime'), bbox_inches='tight')\n",
    "\n",
    "sns.displot(data=df, x='desiredSpeed', y='collisions', kind='kde')\n",
    "plt.title('desiredSpeed - collisions, all frictions')\n",
    "# plt.savefig(charts_path.joinpath('desiredSpeed-collisions'), bbox_inches='tight')\n",
    "\n",
    "sns.displot(data=df, x='friction', y='emergencyBraking', kind='kde')\n",
    "plt.title('friction - emergencyBraking, all desiredSpeeds')\n",
    "# plt.savefig(charts_path.joinpath('friction-emergencyBraking'), bbox_inches='tight')\n",
    "\n",
    "sns.displot(data=df, x='friction', y='speed', kind='kde')\n",
    "plt.title('friction - speed, all desiredSpeeds')\n",
    "# plt.savefig(charts_path.joinpath('friction-speed'), bbox_inches='tight')\n",
    "\n",
    "sns.displot(data=df, x='desiredSpeed', y='emergencyBraking', kind='kde')\n",
    "plt.title('desiredSpeed - emergencyBraking, all frictions')\n",
    "# plt.savefig(charts_path.joinpath('desiredSpeed-emergencyBraking'), bbox_inches='tight')\n",
    "\n",
    "sns.displot(data=df, x='desiredSpeed', y='speed', kind='kde')\n",
    "plt.title('desiredSpeed - speed, all frictions')\n",
    "# plt.savefig(charts_path.joinpath('desiredSpeed-speed'), bbox_inches='tight')\n",
    "'''\n",
    "sns.regplot(data=df[(df['friction'] >= 0.4) & (df['friction'] <= 0.6) & (df['agent'] == 'scratch_s80_f0.5')],\n",
    "            x='desiredSpeed', y='waitingTime', scatter=True, line_kws={\"color\": \"red\"})\n",
    "plt.title('desiredSpeed - waitingTime, 0.5 friction')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6a575b7e8c075bbb",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Define friction ranges (you can adjust these)\n",
    "ranges = [(0.1, 0.3), (0.3, 0.5), (0.5, 0.7), (0.7, 0.9)]\n",
    "colors = ['blue', 'green', 'orange', 'purple']\n",
    "\n",
    "# Loop through ranges and plot each\n",
    "for (low, high), color in zip(ranges, colors):\n",
    "    subset = df[\n",
    "        (df['friction'] >= low) &\n",
    "        (df['friction'] < high) &\n",
    "        (df['agent'] == 'scratch_s80_f0.5')\n",
    "        ]\n",
    "\n",
    "    sns.regplot(\n",
    "        data=subset,\n",
    "        x='desiredSpeed',\n",
    "        y='waitingTime',\n",
    "        scatter=False,\n",
    "        label=f'{low}-{high}',\n",
    "        line_kws={'color': color}\n",
    "    )\n",
    "\n",
    "# Add legend and labels\n",
    "plt.legend(title='Friction Ranges')\n",
    "plt.title('Waiting Time vs Desired Speed by Friction Ranges')\n",
    "plt.xlabel('Desired Speed')\n",
    "plt.ylabel('Waiting Time')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3cec3b864b635930",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Define friction ranges (you can adjust these)\n",
    "ranges = [(0.1, 0.3), (0.3, 0.5), (0.5, 0.7), (0.7, 0.9)]\n",
    "colors = ['blue', 'green', 'orange', 'purple']\n",
    "\n",
    "# Loop through ranges and plot each\n",
    "for (low, high), color in zip(ranges, colors):\n",
    "    subset = df[\n",
    "        (df['friction'] >= low) &\n",
    "        (df['friction'] < high) &\n",
    "        (df['agent'] == 'scratch_s80_f0.5')\n",
    "        ]\n",
    "\n",
    "    sns.regplot(\n",
    "        data=subset,\n",
    "        x='desiredSpeed',\n",
    "        y='collisions',\n",
    "        scatter=False,\n",
    "        label=f'{low}-{high}',\n",
    "        line_kws={'color': color}\n",
    "    )\n",
    "\n",
    "# Add legend and labels\n",
    "plt.legend(title='Friction Ranges')\n",
    "plt.title('Collisions vs Desired Speed by Friction Ranges')\n",
    "plt.xlabel('Desired Speed')\n",
    "plt.ylabel('Collisions')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d928b914fa20c0e0",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data_csv = Path().joinpath('traces', 'traces_all_agents.csv')\n",
    "df = pd.read_csv(data_csv)[['agent', 'desiredSpeed', 'friction', 'speed', 'waitingTime', 'emergencyBraking', 'collisions']]\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Define friction ranges (you can adjust these)\n",
    "ranges = list(df['desiredSpeed'].unique())\n",
    "colors = ['blue', 'green', 'orange', 'purple']\n",
    "\n",
    "# Loop through ranges and plot each\n",
    "for current_speed, color in zip(ranges, colors):\n",
    "    subset = df[\n",
    "        (df['desiredSpeed'] == current_speed) &\n",
    "        (df['agent'] == 'scratch_s80_f0.5')\n",
    "        ]\n",
    "\n",
    "    sns.regplot(\n",
    "        data=subset,\n",
    "        x='friction',\n",
    "        y='speed',\n",
    "        scatter=False,\n",
    "        label=f'{current_speed}',\n",
    "        line_kws={'color': color}\n",
    "    )\n",
    "\n",
    "# Add legend and labels\n",
    "plt.legend(title='Friction Ranges')\n",
    "plt.title('waitingTime vs Friction by Friction Ranges')\n",
    "plt.xlabel('Friction')\n",
    "plt.ylabel('speed')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3bf612e5e064085e",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Define friction ranges (you can adjust these)\n",
    "ranges = list(df['desiredSpeed'].unique())\n",
    "colors = ['blue', 'green', 'orange', 'purple']\n",
    "\n",
    "# Loop through ranges and plot each\n",
    "for current_speed, color in zip(ranges, colors):\n",
    "    subset = df[\n",
    "        (df['desiredSpeed'] == current_speed) &\n",
    "        (df['agent'] == 'scratch_s80_f0.5')\n",
    "        ]\n",
    "\n",
    "    sns.regplot(\n",
    "        data=subset,\n",
    "        x='friction',\n",
    "        y='collisions',\n",
    "        scatter=False,\n",
    "        label=f'{current_speed}',\n",
    "        line_kws={'color': color}\n",
    "    )\n",
    "\n",
    "# Add legend and labels\n",
    "plt.legend(title='Friction Ranges')\n",
    "plt.title('Collisions vs Friction by Friction Ranges')\n",
    "plt.xlabel('Friction')\n",
    "plt.ylabel('Collisions')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8886990b2c39dd7c",
   "metadata": {},
   "source": [
    "Concatenate Summary CSVs"
   ]
  },
  {
   "cell_type": "code",
   "id": "4df2a21ca3b9e06f",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "data_folder = Path().joinpath('traces_paper')\n",
    "summaries = glob.glob(str(data_folder.joinpath('*', '.summary.csv')))\n",
    "\n",
    "dfs = []\n",
    "for summary in summaries:\n",
    "    agent = Path(summary).parent.name[0:-7]\n",
    "    df = pd.read_csv(summary)\n",
    "    df['agent'] = agent\n",
    "    dfs.append(df)\n",
    "\n",
    "final_df = pd.concat(dfs)[\n",
    "    ['agent', 'desiredSpeed', 'friction', 'speed', 'waitingTime', 'emergencyBraking', 'collisions']]\n",
    "\n",
    "final_df.to_csv(data_folder.joinpath('data.csv'), index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1de43ea98a1365db",
   "metadata": {},
   "source": [
    "### Causal Discovery\n",
    "Discover causal graph\n",
    "\n",
    "**Desired Output: Causal Graph XML File**"
   ]
  },
  {
   "cell_type": "code",
   "id": "ca7bf3cc83299253",
   "metadata": {},
   "source": [
    "from castle.common.priori_knowledge import PrioriKnowledge\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from castle.algorithms import PC, DirectLiNGAM\n",
    "from pathlib import Path\n",
    "\n",
    "data_csv = Path().joinpath('traces', 'traces_all_agents.csv')\n",
    "df = pd.read_csv(data_csv)[['desiredSpeed', 'friction', 'speed', 'waitingTime', 'emergencyBraking', 'collisions']]\n",
    "\n",
    "columns = dict(enumerate(df.columns))\n",
    "column_indexes = {value: int(key) for key, value in columns.items()}\n",
    "\n",
    "priori_knowledge = PrioriKnowledge(len(columns))\n",
    "independent_variables = ['desiredSpeed', 'friction']\n",
    "outcome_variables = ['waitingTime', 'collisions']\n",
    "forbidden_edges = [\n",
    "    *({'source': column, 'target': 'desiredSpeed'} for column in column_indexes.keys() if column != 'desiredSpeed'),\n",
    "    *({'source': column, 'target': 'friction'} for column in column_indexes.keys() if column != 'friction'),\n",
    "    *({'source': source_node, 'target': target_node} for source_node, target_node in\n",
    "      itertools.permutations(outcome_variables, 2))\n",
    "]\n",
    "priori_knowledge.add_forbidden_edges(\n",
    "    [(column_indexes[edge['source']], column_indexes[edge['target']]) for edge in forbidden_edges])\n",
    "\n",
    "pc = PC(variant='stable', priori_knowledge=priori_knowledge)\n",
    "pc.learn(df.values.tolist())\n",
    "\n",
    "G_PC = nx.DiGraph(pc.causal_matrix)\n",
    "H_PC = nx.relabel_nodes(G_PC, dict(enumerate(df.columns)))\n",
    "\n",
    "color_map = [\n",
    "    'green' if node in independent_variables else\n",
    "    'red' if H_PC.out_degree(node) == 0 else\n",
    "    'yellow' for node in H_PC.nodes\n",
    "]\n",
    "\n",
    "nx.draw(G=H_PC, node_color=color_map, node_size=1200, arrowsize=30, with_labels=True,\n",
    "        pos=nx.circular_layout(H_PC))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aad7e14038dd022a",
   "metadata": {},
   "source": [
    "Compute directionality of arrows\n",
    "\n",
    "# TODO: Create Pseudo-Code and paste to expose"
   ]
  },
  {
   "cell_type": "code",
   "id": "c7ad297c8cb3cf4f",
   "metadata": {},
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "\n",
    "direction_adjusted_edge_confidence = {}\n",
    "\n",
    "for edge in H_PC.edges():\n",
    "\n",
    "    X = edge[0]\n",
    "    Y = edge[1]\n",
    "    assert H_PC.has_edge(X, Y)\n",
    "\n",
    "    X_data = df[X].values.reshape(-1, 1)\n",
    "    Y_data = df[Y].values.reshape(-1, 1)\n",
    "\n",
    "    # X = f(Y)\n",
    "    model_X_Y = LinearRegression()\n",
    "    model_X_Y.fit(Y_data, X_data)\n",
    "    X_pred = model_X_Y.predict(Y_data)\n",
    "    residuals_X = X_data - X_pred\n",
    "\n",
    "    # Y = g(X)\n",
    "    model_Y_X = LinearRegression()\n",
    "    model_Y_X.fit(X_data, Y_data)\n",
    "    Y_pred = model_Y_X.predict(X_data)\n",
    "    residuals_Y = Y_data - Y_pred\n",
    "\n",
    "    #Spearman's rank correlation\n",
    "    corr_X_resid, p_X_resid = spearmanr(X_data.ravel(), residuals_Y.ravel())\n",
    "    corr_Y_resid, p_Y_resid = spearmanr(Y_data.ravel(), residuals_X.ravel())\n",
    "    print(f'corr_{X}_resid:', corr_X_resid)\n",
    "    print(f'corr_{Y}_resid:', corr_Y_resid)\n",
    "\n",
    "    confidence_abs = abs(abs(corr_Y_resid) - abs(corr_X_resid))\n",
    "    if abs(corr_X_resid) < abs(corr_Y_resid):\n",
    "        print(f\"{X} -> {Y}\")\n",
    "        direction_adjusted_edge_confidence[(X, Y)] = confidence_abs\n",
    "    else:\n",
    "        print(f\"{Y} -> {X}\")\n",
    "        direction_adjusted_edge_confidence[(Y, X)] = confidence_abs\n",
    "\n",
    "    print(\"==============================\")\n",
    "\n",
    "direction_adjusted_edges = []\n",
    "for edge, confidence in direction_adjusted_edge_confidence.items():\n",
    "    if edge not in H_PC.edges():\n",
    "        if confidence < 0.1 or edge[1] in independent_variables:\n",
    "            edge = edge[::-1]\n",
    "    direction_adjusted_edges.append(edge)\n",
    "\n",
    "I_PC = H_PC.copy()\n",
    "I_PC.clear_edges()\n",
    "\n",
    "I_PC.add_edges_from(direction_adjusted_edges)\n",
    "print(direction_adjusted_edge_confidence)\n",
    "\n",
    "color_map = [\n",
    "    'green' if node in independent_variables else\n",
    "    'red' if I_PC.out_degree(node) == 0 else\n",
    "    'yellow' for node in H_PC.nodes\n",
    "]\n",
    "\n",
    "nx.draw(G=I_PC, node_color=color_map, node_size=1200, arrowsize=30, with_labels=True,\n",
    "        pos=nx.circular_layout(H_PC))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d6875ca89b1cb9bc",
   "metadata": {},
   "source": [
    "### Automatically find model from Causal Graph"
   ]
  },
  {
   "cell_type": "code",
   "id": "37dec3b0db0ac56b",
   "metadata": {},
   "source": [
    "causal_graph = I_PC.copy()\n",
    "assert nx.is_directed_acyclic_graph(causal_graph)\n",
    "\n",
    "node_layers = {node: 0 for node in causal_graph.nodes}\n",
    "predecessors = {node: list(causal_graph.predecessors(node)) for node in causal_graph.nodes}\n",
    "visited = set(node for node, predecessor_nodes in predecessors.items() if len(predecessor_nodes) == 0)\n",
    "\n",
    "# Find layers for each node\n",
    "current_layer = max(node_layers.values()) + 1\n",
    "while len(visited) < len(causal_graph.nodes):\n",
    "    unprocessed = set(causal_graph.nodes) - visited\n",
    "    current_nodes = [node for node in unprocessed if visited.issuperset(predecessors[node])]\n",
    "    for node in current_nodes:\n",
    "        node_layers[node] = current_layer\n",
    "    visited.update(current_nodes)\n",
    "    current_layer += 1\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "11820167325fe54e",
   "metadata": {},
   "source": [
    "# TODO: Pseudo Code"
   ]
  },
  {
   "cell_type": "code",
   "id": "4ed21a12ae59ccc4",
   "metadata": {},
   "source": [
    "import pytensor\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "pytensor.config.cxx = ''\n",
    "pytensor.config.floatX = \"float64\"\n",
    "\n",
    "data_csv = Path().joinpath('traces', 'traces_all_agents.csv')\n",
    "df = pd.read_csv(data_csv)[['desiredSpeed', 'friction', 'speed', 'waitingTime', 'emergencyBraking', 'collisions']]\n",
    "\n",
    "\n",
    "df_standardized = (df - df.mean()) / df.std()\n",
    "df_standardized = df_standardized\n",
    "values = {column: df_standardized[column].values for column in df_standardized.columns}\n",
    "\n",
    "alpha = {}\n",
    "beta = {}\n",
    "sigma = {}\n",
    "mu = {}\n",
    "obs = {}\n",
    "independent_data = {}\n",
    "\n",
    "structural_causal_model = pm.Model()\n",
    "\n",
    "with structural_causal_model:\n",
    "    for node in sorted(node_layers.keys(), key=node_layers.__getitem__):\n",
    "        if predecessors[node]:\n",
    "            alpha[node] = pm.Normal(f\"{node} alpha\", mu=0, sigma=10)\n",
    "\n",
    "            current_predecessor_string = ', '.join(f'{index}:{name}' for index, name in enumerate(predecessors[node]))\n",
    "            current_node_beta_name = f\"{node} beta * ({current_predecessor_string})\"\n",
    "\n",
    "            beta[node] = pm.Normal(current_node_beta_name, mu=0, sigma=10, shape=len(predecessors[node]))\n",
    "            sigma[node] = pm.HalfNormal(f\"{node} sigma\", sigma=1)\n",
    "            # maybe try exponential in the future?\n",
    "\n",
    "            mu[node] = alpha[node]\n",
    "            for i, predecessor in enumerate(predecessors[node]):\n",
    "                predictor = independent_data[predecessor] if node_layers[predecessor] == 0 else obs[predecessor]\n",
    "                mu[node] += beta[node][i] * predictor\n",
    "\n",
    "            obs[node] = pm.Normal(f\"{node} obs\", mu=mu[node], sigma=sigma[node], observed=values[node])\n",
    "        else:\n",
    "            # Make sure independent variables are modeled\n",
    "            independent_data[node] = pm.Data(f\"{node}_data\", values[node])\n",
    "\n",
    "    #idata = pm.sample()\n",
    "    #idata.to_netcdf('./scm_full_new.netcdf')\n",
    "\n",
    "    idata = az.InferenceData.from_netcdf('./scm_full.netcdf')\n",
    "\n",
    "az.summary(idata, round_to=2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4ffaa2dbdb5c5575",
   "metadata": {},
   "source": [
    "SCM Direct Effect:"
   ]
  },
  {
   "cell_type": "code",
   "id": "d14c11e5dcf4994c",
   "metadata": {},
   "source": [
    "import pytensor\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "pytensor.config.cxx = ''\n",
    "pytensor.config.floatX = \"float64\"\n",
    "\n",
    "data_csv = Path().joinpath('traces', 'traces_all_agents.csv')\n",
    "df = pd.read_csv(data_csv)[['desiredSpeed', 'friction', 'speed', 'waitingTime', 'emergencyBraking', 'collisions']]\n",
    "df_standardized = (df - df.mean()) / df.std()\n",
    "df_standardized = df_standardized\n",
    "values = {column: df_standardized[column].values for column in df_standardized.columns}\n",
    "\n",
    "outcome_variables = [node for node in I_PC.nodes if I_PC.out_degree(node) == 0]\n",
    "\n",
    "alpha = {}\n",
    "beta = {}\n",
    "sigma = {}\n",
    "mu = {}\n",
    "obs = {}\n",
    "independent_data = {}\n",
    "\n",
    "scm_direct_effect = pm.Model()\n",
    "\n",
    "with scm_direct_effect:\n",
    "    for node in sorted(node_layers.keys(), key=node_layers.__getitem__):\n",
    "        if node in outcome_variables:\n",
    "            alpha[node] = pm.Normal(f\"{node} alpha\", mu=0, sigma=10)\n",
    "\n",
    "            current_predecessor_string = ', '.join(f'{index}:{name}' for index, name in enumerate(predecessors[node]))\n",
    "            current_node_beta_name = f\"{node} beta * ({current_predecessor_string})\"\n",
    "\n",
    "            beta[node] = pm.Normal(current_node_beta_name, mu=0, sigma=10, shape=len(predecessors[node]))\n",
    "            sigma[node] = pm.HalfNormal(f\"{node} sigma\", sigma=1)\n",
    "\n",
    "            mu[node] = alpha[node]\n",
    "            for i, predecessor in enumerate(predecessors[node]):\n",
    "                predictor = independent_data[predecessor]\n",
    "                mu[node] += beta[node][i] * predictor\n",
    "\n",
    "            obs[node] = pm.Normal(f\"{node} obs\", mu=mu[node], sigma=sigma[node], observed=values[node])\n",
    "        else:\n",
    "            # Make sure independent variables are modeled\n",
    "            independent_data[node] = pm.Data(f\"{node}_data\", values[node])\n",
    "\n",
    "    idata = pm.sample(draws=100, tune=100)\n",
    "    idata.to_netcdf(str(Path().joinpath('structural_causal_models', 'scm_direct_effect.netcdf')))\n",
    "\n",
    "    # idata = az.InferenceData.from_netcdf('./scm_full.netcdf')\n",
    "\n",
    "az.summary(idata, round_to=2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d28e34214f07dd6f",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_graph = pm.model_to_networkx(scm_direct_effect)\n",
    "\n",
    "plt.figure(figsize=(20, 20))  # Set viewport size (width, height in inches)\n",
    "\n",
    "nx.draw(\n",
    "    model_graph,\n",
    "    pos=nx.planar_layout(model_graph, scale=5),  # Increase node spacing\n",
    "    with_labels=True,\n",
    "    node_size=5000,  # Increase node size (default 300)\n",
    "    node_color='skyblue',  # Better visibility\n",
    "    edge_color='gray',  # Better visibility\n",
    "    width=3,  # Increase edge thickness (default 1)\n",
    "    font_size=14,  # Increase label size\n",
    "    font_weight='bold',  # Improve label readability\n",
    "    arrowsize=30  # Increase arrow size for directed edges\n",
    ")\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "22925660f40e345e",
   "metadata": {},
   "source": [
    "### Generate Posterior Distribution"
   ]
  },
  {
   "cell_type": "code",
   "id": "c73160fb3bf79f17",
   "metadata": {},
   "source": [
    "FIX_DESIRED_SPEED = True\n",
    "FIX_FRICTION = True\n",
    "DESIRED_SPEED = 13.89\n",
    "FRICTION = 0.75\n",
    "\n",
    "desired_speed = (DESIRED_SPEED - df['desiredSpeed'].mean()) / df['desiredSpeed'].std()\n",
    "desired_speed = [desired_speed] * len(df_standardized)\n",
    "\n",
    "friction = (FRICTION - df['friction'].mean()) / df['friction'].std()\n",
    "friction = [friction] * len(df_standardized)\n",
    "\n",
    "idata = az.InferenceData.from_netcdf('./scm_full.netcdf')\n",
    "thinned_idata = idata.sel(draw=slice(None, None, len(df_standardized)))\n",
    "\n",
    "with structural_causal_model:\n",
    "    if FIX_DESIRED_SPEED:\n",
    "        pm.set_data({'desiredSpeed_data': desired_speed})\n",
    "    if FIX_FRICTION:\n",
    "        pm.set_data({'friction_data': friction})\n",
    "    predictions = pm.sample_posterior_predictive(thinned_idata, predictions=True, var_names=[\"collisions obs\"])\n",
    "\n",
    "### Visualization\n",
    "prediction_data = predictions.predictions\n",
    "prediction_df = prediction_data.to_dataframe()\n",
    "\n",
    "collision_obs = prediction_df['collisions obs'] * df['collisions'].std() + df['collisions'].mean()\n",
    "\n",
    "df_filtered = df.copy()\n",
    "if FIX_DESIRED_SPEED:\n",
    "    df_filtered = df_filtered[(df_filtered['desiredSpeed'] == DESIRED_SPEED)]\n",
    "if FIX_FRICTION:\n",
    "    df_filtered = df_filtered[(df_filtered['friction'] >= FRICTION - 0.05) & (df_filtered['friction'] <= FRICTION + 0.05)]\n",
    "\n",
    "# Sample matching number of predictions\n",
    "sampled_predictions = collision_obs.sample(n=len(df_filtered)).reset_index(drop=True)\n",
    "\n",
    "# Create figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# KDE Plot Comparison\n",
    "sns.kdeplot(collision_obs, label='Predicted', fill=True, ax=ax1)\n",
    "sns.kdeplot(df_filtered['collisions'], label='Observed', fill=True, ax=ax1)\n",
    "ax1.set_title('Density Comparison')\n",
    "ax1.set_xlabel('Collisions')\n",
    "ax1.legend()\n",
    "\n",
    "# Boxplot Comparison\n",
    "boxplot_data = {\n",
    "    'Predicted': sampled_predictions,\n",
    "    'Observed': df_filtered['collisions'].reset_index(drop=True)\n",
    "}\n",
    "sns.boxplot(data=pd.DataFrame(boxplot_data), ax=ax2)\n",
    "ax2.set_title('Distribution Spread')\n",
    "ax2.set_ylabel('Collisions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bed8206ea8459629",
   "metadata": {},
   "source": [
    "### Fit Weibull"
   ]
  },
  {
   "cell_type": "code",
   "id": "eac5ab45018bb2ea",
   "metadata": {},
   "source": [
    "weibull_model = pm.Model()\n",
    "\n",
    "data_csv = Path().joinpath('distribution_shift', 'traces', 'scratch_s80_f1_shift_s80_f0.8.xml', '.summary.csv')\n",
    "df_weibull = pd.read_csv(data_csv)[['collisions']]\n",
    "\n",
    "with weibull_model:\n",
    "    weibull_alpha = pm.HalfNormal('weibull_alpha', sigma=1)  # Shape parameter\n",
    "    weibull_beta = pm.HalfNormal('weibull_beta', sigma=1)    # Scale parameter\n",
    "    weibull_collision_obs = pm.Weibull(\"collisions\", alpha=weibull_alpha, beta=weibull_beta, observed=df_weibull['collisions'])\n",
    "    weibull_idata = pm.sample()\n",
    "\n",
    "az.summary(weibull_idata, round_to=2)\n",
    "\n",
    "with weibull_model:\n",
    "    predictions = pm.sample_posterior_predictive(weibull_idata, predictions=True)\n",
    "\n",
    "predictions"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bd7fc96d3c6ea3a1",
   "metadata": {},
   "source": [
    "prediction_data = predictions.predictions\n",
    "prediction_df = prediction_data.to_dataframe()\n",
    "\n",
    "sns.histplot(data=prediction_df, x='collisions', bins=50)\n",
    "plt.title('Distribution of Collision Column')\n",
    "plt.xlabel('Collision')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
